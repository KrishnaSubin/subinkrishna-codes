{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9637ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5272d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs(*doc_path):\n",
    "    doc_list=[]\n",
    "    for p in doc_path:\n",
    "        data= open(p)\n",
    "        z=data.read()\n",
    "        \n",
    "        punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "        for ele in z:\n",
    "            if ele in punc:\n",
    "                z = z.replace(ele, \"\")\n",
    "        \n",
    "        tokenz=[t for t in z.split()]\n",
    "        \n",
    "        nltk.download('stopwords')\n",
    "        from nltk.corpus import stopwords\n",
    "        sr= stopwords.words(\"english\")\n",
    "        clean_tokenz=[]\n",
    "        for token in tokenz:\n",
    "            \n",
    "            wd=token.lower()\n",
    "            if wd not in sr:\n",
    "                clean_tokenz.append(wd)\n",
    "        \n",
    "        doc_list.append(clean_tokenz)\n",
    "    return doc_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4696e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "doc_lst=docs(r\"C:\\Users\\HP\\Downloads\\text_2.txt\",r\"C:\\Users\\HP\\Downloads\\text3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e69d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['party', 'leo', 'picked', 'attend', 'night', 'held', 'one', 'mansions', 'come', 'equipped', 'private', 'mountain', 'jammed', 'clear', 'upstairs', 'maid', 'artists', 'swamis', 'people', 'prepared', 'dull', 'night', 'wasnt', 'prepared', 'meet', 'panda', 'time', 'didnt', 'know', 'thats', 'knew', 'suddenly', 'spectacular', 'girl', 'glossy', 'white', 'streak', 'satin', 'black', 'hair', 'standing', 'front', 'orange', 'juice', 'vodka', 'one', 'hand', 'expression', 'mild', 'revulsion', 'beautiful', 'face', 'tell', 'silly', 'beard', 'youre', 'male', 'snarled', 'male', 'reached', 'dumped', 'orange', 'juice', 'vodka', 'wasnt', 'anything', 'get', 'sore', 'lots', 'women', 'throw', 'drinks', 'im', 'used', 'happens', 'merely', 'draw', 'full', 'sixfeetfour', 'drip', 'disdainfully', 'drinktosser', 'stalk', 'away', 'theres', 'photographer', 'around', 'pause', 'lash', 'beard', 'couple', 'times', 'camera', 'leo', 'says', 'smart', 'box', 'office', 'wasnt', 'anything', 'get', 'sore', 'thats', 'something', 'sputtered', 'head', 'broke', 'flame', 'without', 'even', 'bothering', 'clear', 'conscience', 'lifted', 'foot', 'planted', 'girls', 'instep', 'hard', 'enough', 'break', 'bones', 'understand', 'enough', 'pressure', 'cause', 'shriek', 'mortal', 'anguish', 'shriek', 'got', 'rousing', 'reaction', 'earnest', 'intellectuals', 'suddenly', 'came', 'boiling', 'toward', 'red', 'wave', 'wrath', 'scrawny', 'blonde', 'built', 'like', 'ruins', 'pompeii', 'lead', 'let', 'girls', 'heard', 'scrawny', 'blonde', 'whinny', 'ten', 'years', 'ago', 'took', 'jujutsu', 'lessons', 'help', 'protect', 'men', 'want', 'see', 'wasted', 'money'], ['wasnt', 'swung', 'lighted', 'boulevard', 'realized', 'picked', 'furious', 'little', 'female', 'striped', 'hair', 'recognized', 'instant', 'yipes', 'squalled', 'bearded', 'gargantua', 'drew', 'back', 'foot', 'aimed', 'quick', 'kick', 'shin', 'opentoed', 'sandal', 'whizzed', 'leg', 'thudded', 'dashboard', 'grabbed', 'foot', 'squalled', 'crumpled', 'like', 'balsa', 'kite', 'screeched', 'bones', 'sticking', 'stop', 'chartreuse', 'tumbrel', 'let', 'stopped', 'car', 'mood', 'felt', 'wasnt', 'safe', 'around', 'dont', 'want', 'rush', 'sis', 'said', 'therell', 'probably', 'broom', 'coming', 'along', 'minute', 'maybe', 'crawl', 'fast', 'grab', 'ride', 'home', 'counted', 'ten', 'cooling', 'faster', 'stripteaser', 'drafty', 'igloo', 'ridiculous', 'sputtered', 'keep', 'blowing', 'top', 'like', 'beginning', 'feel', 'sorry', 'wasnt', 'fault', 'obnoxious', 'dont', 'let', 'throw', 'sighed', 'youre', 'merely', 'acting', 'normal', 'everybody', 'hates']]\n"
     ]
    }
   ],
   "source": [
    "print(doc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493082bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb8a13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = []\n",
    "for i in doc_lst:\n",
    "    txt = txt + i\n",
    "unique_words=[]\n",
    "for t in txt:\n",
    "    if t not in unique_words:\n",
    "        unique_words.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3500665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['party',\n",
       " 'leo',\n",
       " 'picked',\n",
       " 'attend',\n",
       " 'night',\n",
       " 'held',\n",
       " 'one',\n",
       " 'mansions',\n",
       " 'come',\n",
       " 'equipped',\n",
       " 'private',\n",
       " 'mountain',\n",
       " 'jammed',\n",
       " 'clear',\n",
       " 'upstairs',\n",
       " 'maid',\n",
       " 'artists',\n",
       " 'swamis',\n",
       " 'people',\n",
       " 'prepared',\n",
       " 'dull',\n",
       " 'wasnt',\n",
       " 'meet',\n",
       " 'panda',\n",
       " 'time',\n",
       " 'didnt',\n",
       " 'know',\n",
       " 'thats',\n",
       " 'knew',\n",
       " 'suddenly',\n",
       " 'spectacular',\n",
       " 'girl',\n",
       " 'glossy',\n",
       " 'white',\n",
       " 'streak',\n",
       " 'satin',\n",
       " 'black',\n",
       " 'hair',\n",
       " 'standing',\n",
       " 'front',\n",
       " 'orange',\n",
       " 'juice',\n",
       " 'vodka',\n",
       " 'hand',\n",
       " 'expression',\n",
       " 'mild',\n",
       " 'revulsion',\n",
       " 'beautiful',\n",
       " 'face',\n",
       " 'tell',\n",
       " 'silly',\n",
       " 'beard',\n",
       " 'youre',\n",
       " 'male',\n",
       " 'snarled',\n",
       " 'reached',\n",
       " 'dumped',\n",
       " 'anything',\n",
       " 'get',\n",
       " 'sore',\n",
       " 'lots',\n",
       " 'women',\n",
       " 'throw',\n",
       " 'drinks',\n",
       " 'im',\n",
       " 'used',\n",
       " 'happens',\n",
       " 'merely',\n",
       " 'draw',\n",
       " 'full',\n",
       " 'sixfeetfour',\n",
       " 'drip',\n",
       " 'disdainfully',\n",
       " 'drinktosser',\n",
       " 'stalk',\n",
       " 'away',\n",
       " 'theres',\n",
       " 'photographer',\n",
       " 'around',\n",
       " 'pause',\n",
       " 'lash',\n",
       " 'couple',\n",
       " 'times',\n",
       " 'camera',\n",
       " 'says',\n",
       " 'smart',\n",
       " 'box',\n",
       " 'office',\n",
       " 'something',\n",
       " 'sputtered',\n",
       " 'head',\n",
       " 'broke',\n",
       " 'flame',\n",
       " 'without',\n",
       " 'even',\n",
       " 'bothering',\n",
       " 'conscience',\n",
       " 'lifted',\n",
       " 'foot',\n",
       " 'planted',\n",
       " 'girls',\n",
       " 'instep',\n",
       " 'hard',\n",
       " 'enough',\n",
       " 'break',\n",
       " 'bones',\n",
       " 'understand',\n",
       " 'pressure',\n",
       " 'cause',\n",
       " 'shriek',\n",
       " 'mortal',\n",
       " 'anguish',\n",
       " 'got',\n",
       " 'rousing',\n",
       " 'reaction',\n",
       " 'earnest',\n",
       " 'intellectuals',\n",
       " 'came',\n",
       " 'boiling',\n",
       " 'toward',\n",
       " 'red',\n",
       " 'wave',\n",
       " 'wrath',\n",
       " 'scrawny',\n",
       " 'blonde',\n",
       " 'built',\n",
       " 'like',\n",
       " 'ruins',\n",
       " 'pompeii',\n",
       " 'lead',\n",
       " 'let',\n",
       " 'heard',\n",
       " 'whinny',\n",
       " 'ten',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'took',\n",
       " 'jujutsu',\n",
       " 'lessons',\n",
       " 'help',\n",
       " 'protect',\n",
       " 'men',\n",
       " 'want',\n",
       " 'see',\n",
       " 'wasted',\n",
       " 'money',\n",
       " 'swung',\n",
       " 'lighted',\n",
       " 'boulevard',\n",
       " 'realized',\n",
       " 'furious',\n",
       " 'little',\n",
       " 'female',\n",
       " 'striped',\n",
       " 'recognized',\n",
       " 'instant',\n",
       " 'yipes',\n",
       " 'squalled',\n",
       " 'bearded',\n",
       " 'gargantua',\n",
       " 'drew',\n",
       " 'back',\n",
       " 'aimed',\n",
       " 'quick',\n",
       " 'kick',\n",
       " 'shin',\n",
       " 'opentoed',\n",
       " 'sandal',\n",
       " 'whizzed',\n",
       " 'leg',\n",
       " 'thudded',\n",
       " 'dashboard',\n",
       " 'grabbed',\n",
       " 'crumpled',\n",
       " 'balsa',\n",
       " 'kite',\n",
       " 'screeched',\n",
       " 'sticking',\n",
       " 'stop',\n",
       " 'chartreuse',\n",
       " 'tumbrel',\n",
       " 'stopped',\n",
       " 'car',\n",
       " 'mood',\n",
       " 'felt',\n",
       " 'safe',\n",
       " 'dont',\n",
       " 'rush',\n",
       " 'sis',\n",
       " 'said',\n",
       " 'therell',\n",
       " 'probably',\n",
       " 'broom',\n",
       " 'coming',\n",
       " 'along',\n",
       " 'minute',\n",
       " 'maybe',\n",
       " 'crawl',\n",
       " 'fast',\n",
       " 'grab',\n",
       " 'ride',\n",
       " 'home',\n",
       " 'counted',\n",
       " 'cooling',\n",
       " 'faster',\n",
       " 'stripteaser',\n",
       " 'drafty',\n",
       " 'igloo',\n",
       " 'ridiculous',\n",
       " 'keep',\n",
       " 'blowing',\n",
       " 'top',\n",
       " 'beginning',\n",
       " 'feel',\n",
       " 'sorry',\n",
       " 'fault',\n",
       " 'obnoxious',\n",
       " 'sighed',\n",
       " 'acting',\n",
       " 'normal',\n",
       " 'everybody',\n",
       " 'hates']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214dc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(word):\n",
    "    vect__r=[]\n",
    "    for i in doc_lst:\n",
    "        w=word.lower()\n",
    "        if w in i:\n",
    "            vect__r.append(1)\n",
    "        else:\n",
    "            vect__r.append(0)\n",
    "    return vect__r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec6efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dict={}\n",
    "for i in unique_words:\n",
    "    vector_dict[i] = vector(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7841239b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'party': [1, 0],\n",
       " 'leo': [1, 0],\n",
       " 'picked': [1, 1],\n",
       " 'attend': [1, 0],\n",
       " 'night': [1, 0],\n",
       " 'held': [1, 0],\n",
       " 'one': [1, 0],\n",
       " 'mansions': [1, 0],\n",
       " 'come': [1, 0],\n",
       " 'equipped': [1, 0],\n",
       " 'private': [1, 0],\n",
       " 'mountain': [1, 0],\n",
       " 'jammed': [1, 0],\n",
       " 'clear': [1, 0],\n",
       " 'upstairs': [1, 0],\n",
       " 'maid': [1, 0],\n",
       " 'artists': [1, 0],\n",
       " 'swamis': [1, 0],\n",
       " 'people': [1, 0],\n",
       " 'prepared': [1, 0],\n",
       " 'dull': [1, 0],\n",
       " 'wasnt': [1, 1],\n",
       " 'meet': [1, 0],\n",
       " 'panda': [1, 0],\n",
       " 'time': [1, 0],\n",
       " 'didnt': [1, 0],\n",
       " 'know': [1, 0],\n",
       " 'thats': [1, 0],\n",
       " 'knew': [1, 0],\n",
       " 'suddenly': [1, 0],\n",
       " 'spectacular': [1, 0],\n",
       " 'girl': [1, 0],\n",
       " 'glossy': [1, 0],\n",
       " 'white': [1, 0],\n",
       " 'streak': [1, 0],\n",
       " 'satin': [1, 0],\n",
       " 'black': [1, 0],\n",
       " 'hair': [1, 1],\n",
       " 'standing': [1, 0],\n",
       " 'front': [1, 0],\n",
       " 'orange': [1, 0],\n",
       " 'juice': [1, 0],\n",
       " 'vodka': [1, 0],\n",
       " 'hand': [1, 0],\n",
       " 'expression': [1, 0],\n",
       " 'mild': [1, 0],\n",
       " 'revulsion': [1, 0],\n",
       " 'beautiful': [1, 0],\n",
       " 'face': [1, 0],\n",
       " 'tell': [1, 0],\n",
       " 'silly': [1, 0],\n",
       " 'beard': [1, 0],\n",
       " 'youre': [1, 1],\n",
       " 'male': [1, 0],\n",
       " 'snarled': [1, 0],\n",
       " 'reached': [1, 0],\n",
       " 'dumped': [1, 0],\n",
       " 'anything': [1, 0],\n",
       " 'get': [1, 0],\n",
       " 'sore': [1, 0],\n",
       " 'lots': [1, 0],\n",
       " 'women': [1, 0],\n",
       " 'throw': [1, 1],\n",
       " 'drinks': [1, 0],\n",
       " 'im': [1, 0],\n",
       " 'used': [1, 0],\n",
       " 'happens': [1, 0],\n",
       " 'merely': [1, 1],\n",
       " 'draw': [1, 0],\n",
       " 'full': [1, 0],\n",
       " 'sixfeetfour': [1, 0],\n",
       " 'drip': [1, 0],\n",
       " 'disdainfully': [1, 0],\n",
       " 'drinktosser': [1, 0],\n",
       " 'stalk': [1, 0],\n",
       " 'away': [1, 0],\n",
       " 'theres': [1, 0],\n",
       " 'photographer': [1, 0],\n",
       " 'around': [1, 1],\n",
       " 'pause': [1, 0],\n",
       " 'lash': [1, 0],\n",
       " 'couple': [1, 0],\n",
       " 'times': [1, 0],\n",
       " 'camera': [1, 0],\n",
       " 'says': [1, 0],\n",
       " 'smart': [1, 0],\n",
       " 'box': [1, 0],\n",
       " 'office': [1, 0],\n",
       " 'something': [1, 0],\n",
       " 'sputtered': [1, 1],\n",
       " 'head': [1, 0],\n",
       " 'broke': [1, 0],\n",
       " 'flame': [1, 0],\n",
       " 'without': [1, 0],\n",
       " 'even': [1, 0],\n",
       " 'bothering': [1, 0],\n",
       " 'conscience': [1, 0],\n",
       " 'lifted': [1, 0],\n",
       " 'foot': [1, 1],\n",
       " 'planted': [1, 0],\n",
       " 'girls': [1, 0],\n",
       " 'instep': [1, 0],\n",
       " 'hard': [1, 0],\n",
       " 'enough': [1, 0],\n",
       " 'break': [1, 0],\n",
       " 'bones': [1, 1],\n",
       " 'understand': [1, 0],\n",
       " 'pressure': [1, 0],\n",
       " 'cause': [1, 0],\n",
       " 'shriek': [1, 0],\n",
       " 'mortal': [1, 0],\n",
       " 'anguish': [1, 0],\n",
       " 'got': [1, 0],\n",
       " 'rousing': [1, 0],\n",
       " 'reaction': [1, 0],\n",
       " 'earnest': [1, 0],\n",
       " 'intellectuals': [1, 0],\n",
       " 'came': [1, 0],\n",
       " 'boiling': [1, 0],\n",
       " 'toward': [1, 0],\n",
       " 'red': [1, 0],\n",
       " 'wave': [1, 0],\n",
       " 'wrath': [1, 0],\n",
       " 'scrawny': [1, 0],\n",
       " 'blonde': [1, 0],\n",
       " 'built': [1, 0],\n",
       " 'like': [1, 1],\n",
       " 'ruins': [1, 0],\n",
       " 'pompeii': [1, 0],\n",
       " 'lead': [1, 0],\n",
       " 'let': [1, 1],\n",
       " 'heard': [1, 0],\n",
       " 'whinny': [1, 0],\n",
       " 'ten': [1, 1],\n",
       " 'years': [1, 0],\n",
       " 'ago': [1, 0],\n",
       " 'took': [1, 0],\n",
       " 'jujutsu': [1, 0],\n",
       " 'lessons': [1, 0],\n",
       " 'help': [1, 0],\n",
       " 'protect': [1, 0],\n",
       " 'men': [1, 0],\n",
       " 'want': [1, 1],\n",
       " 'see': [1, 0],\n",
       " 'wasted': [1, 0],\n",
       " 'money': [1, 0],\n",
       " 'swung': [0, 1],\n",
       " 'lighted': [0, 1],\n",
       " 'boulevard': [0, 1],\n",
       " 'realized': [0, 1],\n",
       " 'furious': [0, 1],\n",
       " 'little': [0, 1],\n",
       " 'female': [0, 1],\n",
       " 'striped': [0, 1],\n",
       " 'recognized': [0, 1],\n",
       " 'instant': [0, 1],\n",
       " 'yipes': [0, 1],\n",
       " 'squalled': [0, 1],\n",
       " 'bearded': [0, 1],\n",
       " 'gargantua': [0, 1],\n",
       " 'drew': [0, 1],\n",
       " 'back': [0, 1],\n",
       " 'aimed': [0, 1],\n",
       " 'quick': [0, 1],\n",
       " 'kick': [0, 1],\n",
       " 'shin': [0, 1],\n",
       " 'opentoed': [0, 1],\n",
       " 'sandal': [0, 1],\n",
       " 'whizzed': [0, 1],\n",
       " 'leg': [0, 1],\n",
       " 'thudded': [0, 1],\n",
       " 'dashboard': [0, 1],\n",
       " 'grabbed': [0, 1],\n",
       " 'crumpled': [0, 1],\n",
       " 'balsa': [0, 1],\n",
       " 'kite': [0, 1],\n",
       " 'screeched': [0, 1],\n",
       " 'sticking': [0, 1],\n",
       " 'stop': [0, 1],\n",
       " 'chartreuse': [0, 1],\n",
       " 'tumbrel': [0, 1],\n",
       " 'stopped': [0, 1],\n",
       " 'car': [0, 1],\n",
       " 'mood': [0, 1],\n",
       " 'felt': [0, 1],\n",
       " 'safe': [0, 1],\n",
       " 'dont': [0, 1],\n",
       " 'rush': [0, 1],\n",
       " 'sis': [0, 1],\n",
       " 'said': [0, 1],\n",
       " 'therell': [0, 1],\n",
       " 'probably': [0, 1],\n",
       " 'broom': [0, 1],\n",
       " 'coming': [0, 1],\n",
       " 'along': [0, 1],\n",
       " 'minute': [0, 1],\n",
       " 'maybe': [0, 1],\n",
       " 'crawl': [0, 1],\n",
       " 'fast': [0, 1],\n",
       " 'grab': [0, 1],\n",
       " 'ride': [0, 1],\n",
       " 'home': [0, 1],\n",
       " 'counted': [0, 1],\n",
       " 'cooling': [0, 1],\n",
       " 'faster': [0, 1],\n",
       " 'stripteaser': [0, 1],\n",
       " 'drafty': [0, 1],\n",
       " 'igloo': [0, 1],\n",
       " 'ridiculous': [0, 1],\n",
       " 'keep': [0, 1],\n",
       " 'blowing': [0, 1],\n",
       " 'top': [0, 1],\n",
       " 'beginning': [0, 1],\n",
       " 'feel': [0, 1],\n",
       " 'sorry': [0, 1],\n",
       " 'fault': [0, 1],\n",
       " 'obnoxious': [0, 1],\n",
       " 'sighed': [0, 1],\n",
       " 'acting': [0, 1],\n",
       " 'normal': [0, 1],\n",
       " 'everybody': [0, 1],\n",
       " 'hates': [0, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc10a766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query:party not picked\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "query = input('Enter your query:')\n",
    "query = word_tokenize(query)\n",
    "connecting_words = []\n",
    "cnt = 1\n",
    "different_words = []\n",
    "\n",
    "for word in query:\n",
    "    if word.lower() != \"and\" and word.lower() != \"or\" and word.lower() != \"not\":\n",
    "        different_words.append(word.lower())\n",
    "    else:\n",
    "        connecting_words.append(word.lower())\n",
    "\n",
    "\n",
    "if connecting_words[0] == \"and\":\n",
    "    bitwise_op = np.array(vector_dict[different_words[0]]) & np.array(vector_dict[different_words[1]])\n",
    "elif connecting_words[0] == \"or\":\n",
    "    bitwise_op = np.array(vector_dict[different_words[0]]) | np.array(vector_dict[different_words[1]])\n",
    "elif connecting_words[0] == \"not\":\n",
    "    v= 1 - np.array(vector_dict[different_words[1]])\n",
    "    bitwise_op= np.array(vector_dict[different_words[0]]) & np.array(v)\n",
    "    \n",
    "    \n",
    "    \n",
    "connecting_words.pop(0)\n",
    "different_words.pop(0)\n",
    "different_words.pop(0)\n",
    "\n",
    "for word in connecting_words:\n",
    "    if word == \"and\":\n",
    "        bitwise_op = bitwise_op & np.array(vector_dict[different_words[0]])\n",
    "        connecting_words.pop(0)\n",
    "        different_words.pop(0)\n",
    "    elif word == \"or\":\n",
    "        bitwise_op = bitwise_op | np.array(vector_dict[different_words[0]])\n",
    "        connecting_words.pop(0)\n",
    "        different_words.pop(0)\n",
    "    elif word == \"not\":\n",
    "        v= 1-np.array(vector_dict[different_words[0]])\n",
    "        bitwise_op= np.array(vector_dict[different_words[0]]) & np.array(v)\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "print(bitwise_op)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea550a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e221a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc6c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6bb5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
